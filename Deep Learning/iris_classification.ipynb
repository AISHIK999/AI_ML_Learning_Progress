{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Classification of flowers based on given data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A neural network model to classify flowers into their respective species based on some parameters (presented in the iris.csv dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare the dataset for deep learning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Load the data into a pandas dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris dataframe:\n",
      "     Sepal.Length  Sepal.Width  Petal.Length  Petal.Width    Species\n",
      "0             5.1          3.5           1.4          0.2     setosa\n",
      "1             4.9          3.0           1.4          0.2     setosa\n",
      "2             4.7          3.2           1.3          0.2     setosa\n",
      "3             4.6          3.1           1.5          0.2     setosa\n",
      "4             5.0          3.6           1.4          0.2     setosa\n",
      "..            ...          ...           ...          ...        ...\n",
      "145           6.7          3.0           5.2          2.3  virginica\n",
      "146           6.3          2.5           5.0          1.9  virginica\n",
      "147           6.5          3.0           5.2          2.0  virginica\n",
      "148           6.2          3.4           5.4          2.3  virginica\n",
      "149           5.9          3.0           5.1          1.8  virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the iris dataset into a pandas dataframe\n",
    "import pandas as pd\n",
    "\n",
    "iris_dataframe = pd.read_csv(\"data/iris.csv\")\n",
    "print(f\"Iris dataframe:\\n{iris_dataframe}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Convert the string target variable \"Species\" into a numeric format"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# sklearn label encoder converts string into numeric values\n",
    "# We will use the library to convert the \"species\" feature set, which is our target variable, into numeric values\n",
    "# This makes the data usable by our model\n",
    "from sklearn import preprocessing\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "iris_dataframe[\"Species\"] = label_encoder.fit_transform(iris_dataframe[\"Species\"])\n",
    "\n",
    "# Convert the data into numpy array\n",
    "iris_numpy_array = iris_dataframe.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Spilt the array dataset into feature and target variable"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features before scaling:\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "\n",
      "Target before scaling:\n",
      "[0. 0. 0. 0. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# X represents feature variables and Y represents target variables\n",
    "\"\"\"\n",
    "[a , b] = select row index \"a\" and column index \"b\" respectively from a numpy array\n",
    "\n",
    "[0:a , :b] = select first \"a\" rows and first \"b\" columns (both representations are similar]\n",
    "\n",
    "[: , :] = select all rows and columns\n",
    "\n",
    "[a:x , b:y] = select all rows from row index \"a\" to row index \"x\" and select all columns from column index \"b\" to column index \"y\"\n",
    "\n",
    "[:-x , -y] = select all rows except the last \"x\" rows and select last \"y\" columns\n",
    "\"\"\"\n",
    "X_data = iris_numpy_array[:, 0:4]       # Select all rows and first 4 columns\n",
    "Y_data = iris_numpy_array[:, 4]         # Select all rows and 4th column index (\"Species\" target feature)\n",
    "\n",
    "print(f\"Features before scaling:\\n{X_data[:5, :]}\\n\")       # Print the features of first 5 rows and all corresponding columns\n",
    "print(f\"Target before scaling:\\n{Y_data[:5]}\\n\")            # Print the first 5 instances of the target (\"Y_data\") array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Scale the input dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features after classification:\n",
      "[[-0.90068117  1.01900435 -1.34022653 -1.3154443 ]\n",
      " [-1.14301691 -0.13197948 -1.34022653 -1.3154443 ]\n",
      " [-1.38535265  0.32841405 -1.39706395 -1.3154443 ]\n",
      " [-1.50652052  0.09821729 -1.2833891  -1.3154443 ]\n",
      " [-1.02184904  1.24920112 -1.34022653 -1.3154443 ]]\n",
      "\n",
      "Target after one-hot encoding:\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# From the feature variables, it can be seen that they need to scaled to the same level to be used by the neural network model\n",
    "# We will use the StandardScaler() from the sklearn library for this purpose\n",
    "# We use the one-hot encoding function on the target variable as this is a multi-class classification problem\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create a scaler model that is fit on the input data\n",
    "scaler_model = StandardScaler().fit(X_data)\n",
    "\n",
    "# Scale the numeric feature variables\n",
    "X_data = scaler_model.transform(X_data)\n",
    "\n",
    "# Scale the target variable as one-hot encoding array\n",
    "Y_data = tf.keras.utils.to_categorical(Y_data, 3)   # We created 3 columns, each of which represents a species (\"setosa\", \"versicolor\" and \"virginica\") as shown in the dataset\n",
    "\n",
    "print(f\"Features after classification:\\n{X_data[:5, :]}\\n\")\n",
    "print(f\"Target after one-hot encoding:\\n{Y_data[:5, :]}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "5. Split the scaled dataset into training and testing dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the training dataset into testing and training dataset\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.1)      # Use 10% of the entire dataset for testing dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create the Neural Network model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " first_hidden_layer (Dense)  (None, 128)               640       \n",
      "                                                                 \n",
      " second_hidden_layer (Dense)  (None, 128)              16512     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,539\n",
      "Trainable params: 17,539\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "=================================================================\n",
      "First hidden layer has 128 nodes and 640 parameters\n",
      "Parameter = weight + bias\n",
      "Weight = input * node (4 * 128 = 512)\n",
      "Bias = Number of nodes (128)\n",
      "Thus the parameters = 512 + 128 = 640\n",
      "Similar case is present in all the layers\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "class_num = 3       # There are 3 classes of flowers in the dataset\n",
    "neural_network_model = tf.keras.models.Sequential()     # Creating a sequential model\n",
    "\n",
    "# FIRST HIDDEN LAYER\n",
    "neural_network_model.add(keras.layers.Dense(128,    # 128 nodes\n",
    "                             input_shape=(4,),      # Provide with 4 inputs (sepal length and width, petal length and width\n",
    "                             name='first_hidden_layer',\n",
    "                             activation='relu'))    # Rectified linear unit activation function\n",
    "\n",
    "# SECOND HIDDEN LAYER\n",
    "neural_network_model.add(keras.layers.Dense(128,\n",
    "                             name='second_hidden_layer',\n",
    "                             activation='relu'))\n",
    "\n",
    "# OUTPUT LAYER\n",
    "neural_network_model.add(keras.layers.Dense(class_num,      # Number of classes of target variable (setosa, versicolor, virginica)\n",
    "                             name='output_layer',\n",
    "                             activation='softmax'))         # Activation function\n",
    "\n",
    "# Compile model uses categorical_crossentropy as this is a multi-class classification model\n",
    "# We will measure the accuracy. Our aim is to have greater accuracy\n",
    "neural_network_model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "summary = neural_network_model.summary()\n",
    "print(\"=================================================================\\nFirst hidden layer has 128 nodes and 640 parameters\\nParameter = weight + bias\\nWeight = input * node (4 * 128 = 512)\\nBias = Number of nodes (128)\\nThus the parameters = 512 + 128 = 640\\nSimilar case is present in all the layers\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train and evaluate the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4/4 [==============================] - 2s 146ms/step - loss: 0.8854 - accuracy: 0.7315 - val_loss: 0.6501 - val_accuracy: 0.7407\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6051 - accuracy: 0.8333 - val_loss: 0.5274 - val_accuracy: 0.7407\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4935 - accuracy: 0.8241 - val_loss: 0.4695 - val_accuracy: 0.7407\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4293 - accuracy: 0.8241 - val_loss: 0.4104 - val_accuracy: 0.7778\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3909 - accuracy: 0.8519 - val_loss: 0.4073 - val_accuracy: 0.7778\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.3574 - accuracy: 0.8333 - val_loss: 0.3683 - val_accuracy: 0.7778\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3329 - accuracy: 0.8611 - val_loss: 0.3560 - val_accuracy: 0.7778\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.3114 - accuracy: 0.8519 - val_loss: 0.3418 - val_accuracy: 0.7778\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2949 - accuracy: 0.8611 - val_loss: 0.3516 - val_accuracy: 0.7778\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2745 - accuracy: 0.8519 - val_loss: 0.2975 - val_accuracy: 0.8148\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2586 - accuracy: 0.8704 - val_loss: 0.2771 - val_accuracy: 0.8519\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2437 - accuracy: 0.8981 - val_loss: 0.2949 - val_accuracy: 0.7778\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.2284 - accuracy: 0.8981 - val_loss: 0.2361 - val_accuracy: 0.8889\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2168 - accuracy: 0.9074 - val_loss: 0.2336 - val_accuracy: 0.8889\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2114 - accuracy: 0.9259 - val_loss: 0.2206 - val_accuracy: 0.8889\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1932 - accuracy: 0.9444 - val_loss: 0.2183 - val_accuracy: 0.9259\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.1792 - accuracy: 0.9352 - val_loss: 0.1825 - val_accuracy: 0.9259\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1670 - accuracy: 0.9537 - val_loss: 0.2079 - val_accuracy: 0.9259\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1574 - accuracy: 0.9630 - val_loss: 0.1922 - val_accuracy: 0.9259\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1479 - accuracy: 0.9722 - val_loss: 0.2124 - val_accuracy: 0.9259\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 720x432 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0537 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.05365125462412834, 1.0]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For training a model, we need to pass the entire training dataset into the model\n",
    "# Since the entirety of the dataset is too large, we break it down into smaller portions called \"Batches\"\n",
    "# Multiple batches like this constitute an \"Epoch\"\n",
    "# One epoch means the entire dataset has been passed forward and backward once through the NN model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the model and store results in model_data\n",
    "trained_model=neural_network_model.fit(X_train, Y_train,\n",
    "                                       batch_size=32,           # We will split the training dataset into 32 batches\n",
    "                                       epochs=20,               # There will be 10 epochs to marl the completion of NN model training\n",
    "                                       verbose=1,               # Enable verbose logging\n",
    "                                       validation_split=0.2)    # Validation split marks the portion of the training data used to validate the results of the NN model after each epoch. Here 20% of the training data is used\n",
    "\n",
    "# Plot accuracy of the model after each epoch.\n",
    "pd.DataFrame(trained_model.history)[\"accuracy\"].plot(figsize=(10, 6))\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "#Evaluate the model against the test dataset and print results\n",
    "neural_network_model.evaluate(X_test,Y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save the model for use"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: iris_prediction\\assets\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " first_hidden_layer (Dense)  (None, 128)               640       \n",
      "                                                                 \n",
      " second_hidden_layer (Dense)  (None, 128)              16512     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,539\n",
      "Trainable params: 17,539\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/a/42121886\n",
    "# To disable the INFO spam in summary logs\n",
    "\n",
    "# Save model\n",
    "neural_network_model.save(\"iris_prediction\")\n",
    "\n",
    "# Load model\n",
    "saved_iris_model = keras.models.load_model(\"iris_prediction\")\n",
    "\n",
    "# Print model summary\n",
    "saved_iris_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test the NN model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 172ms/step\n",
      "Raw prediction probabilities: [[0.02186031 0.724861   0.25327867]]\n",
      "Prediction is  ['versicolor']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Prediction data (sepal length, sepal width, petal length, petal width)\n",
    "prediction_input = [[6.6, 3.1 , 4.4, 1.4]]\n",
    "\n",
    "# Scale the prediction with the scaled model created before\n",
    "scaled_input = scaler_model.transform(prediction_input)\n",
    "\n",
    "# Get raw prediction probabilities\n",
    "raw_prediction = neural_network_model.predict(scaled_input)\n",
    "print(\"Raw prediction probabilities:\" , raw_prediction)\n",
    "\n",
    "# Predict result\n",
    "prediction = np.argmax(raw_prediction)\n",
    "print(\"Prediction is \", label_encoder.inverse_transform([prediction]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}